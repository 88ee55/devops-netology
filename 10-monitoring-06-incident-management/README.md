# Домашнее задание к занятию "10.06. Инцидент-менеджмент"

## Задание 1

Составьте постмотрем, на основе реального сбоя системы Github в 2018 году.

Информация о сбое доступна [в виде краткой выжимки на русском языке](https://habr.com/ru/post/427301/) , а
также [развёрнуто на английском языке](https://github.blog/2018-10-30-oct21-post-incident-analysis/).

| Postmortem | Сбой Github |
|----------:|:----------|
| Краткое описание инцидента | 21 октября в 22:52 UTC Деградации нескольких внутренних систем Github на 24 часа и 11 минут |
| Предшествующие события | 21 октября в 22:52 UTC плановые ремонтные работы по замене неисправного оптического оборудования 100G |
| Причина инцидента | Потеря связи между сетевым узлом на Восточном побережье (US East Coast) и основным дата-центром на Восточном побережье |
| Воздействие | Пользователи не могли оставлять PR и issues, управлять аутентификацией, координировать фоновые процессы, кроме того, не работали web-хуки, а также сайты на GitHub Pages течение 24 часов 11 минут |
| Обнаружение | 21 октября 2018 22:54 UTC внутренние системы мониторинга начали генерировать оповещения, указывающие на многочисленные сбои в работе систем. К 23:02 инженеры первой группы реагирования определили, что топологии для многочисленных кластеров БД находятся в не корректном состоянии. При запросе API Orchestrator отображалась топология репликации БД, содержащая только серверы из западного ЦО |
| Реакция |  Группа реагирования приняла решение вручную заблокировать внутренние инструменты развертывания, чтобы предотвратить внесение каких-либо дополнительных изменений. Команда перевела сайт в желтый статус. Это действие автоматически перевело ситуацию в активный инцидент и отправило предупреждение координатору инцидента. Координатор инцидента через две минуты принял решение изменить статус на красный. Защита конфиденциальности и целостности пользовательских данных поставлена выше, чем продолжительная деградация сервиса. |
| Восстановление| План состоял в том, чтобы восстановиться из резервных копий, синхронизировать реплики, вернуться к стабильной топологии обслуживания и затем возобновить обработку заданий в очереди. |
| Таймлайн | <ul><li> 21 октября 2018, 22:52 UTC - потеря связи между US East Coast network hub и US East Coast data center</li><li> 21 октября 2018 22:54 UTC - внутренние системы мониторинга начали генерировать оповещения, указывающие на многочисленные сбои в работе систем</li><li> 21 октября 2018 23:02 UTC - появляется понимание, что топология кластера БД в некорректном состоянии.</li><li> 21 октября 2018 23:07 UTC - группа реагирования ручную заблокировала внутренние средства развёртывания</li><li> 21 октября 2018 23:09 UTC - установлен жёлтый статус работоспособности сайта</li><li> 21 октября 2018 23:11 UTC - подключился координатор инцидента и принял решение изменить статус на красный</li><li> 21 октября 2018 23:13 UTC - привлечены дополнительные разработчики из инженерной группы БД. Они начали исследовать текущее состояние, чтобы определить, какие действия необходимо предпринять, чтобы вручную настроить базу данных Восточного ЦОД в качестве основной для каждого кластера и перестроить топологию репликации. Выставлен приоритет на защиту конфиденциальности и целостности пользовательских данных.</li><li> 21 октября 2018 23:19 UTC - принято решение остановить выполнение заданий, которые записывают метаданные, а также приостановить доставку web-хуков и сборки GitHub Pages</li><li> 22 октября 2018 00:05 UTC - разработка плана по восстановлению из резервных копий, синхронизации реплик на обоих ЦОД, вернуться к стабильной топологии обслуживания и затем возобновить обработку заданий в очереди. Обновлён статус для информирования пользователей.</li><li> 22 октября 2018 00:41 UTC - инициирован процесс резервного копирования всех затронутых кластеров MySQL</li><li> 22 октября 2018 06:51 UTC - несколько кластеров в восточном ЦОД завершили восстановление из резервных копий и начали реплицировать новые данные с Западным побережьем. Это привело к замедлению загрузки страниц, которые выполняли операцию записи через всю страну, но чтение страниц из этих кластеров БД возвращало актуальные результаты, если запрос чтения попадал на только что восстановленную реплику. Другие более крупные кластеры БД продолжали восстанавливаться.</li><li> 22 октября 2018 07:46 UTC - GitHub опубликовал информационное сообщение в блоге.</li><li> 22 октября 2018 11:12 UTC - все первичные базы данных снова установлены на Восточном ЦОД. Часть реплик всё ещё отставала от основной БД.</li><li> 22 октября 2018 13:15 UTC - группа реагирования на инциденты провела обсуждение дальнейших действий. Задержки репликации увеличились из-за пиковой нагрузки.</li><li> 22 октября 2018 16:24 UTC - реплики синхронизированы, выполнено аварийное переключение на исходную топологию. Статус службы всё ещё красный, началась обработка накопленных данных.</li><li> 22 октября 2018 16:45 UTC - балансировку увеличившейся нагрузки и обработка очереди web-хуков и сборок страниц.</li><li> 22 октября 2018 23:03 UTC - все незавершенные веб-перехватчики и сборки страниц обработаны, и целостность и правильность работы всех систем подтверждены. Статус сайта обновлен на зеленый.</li></ul> |
| Последующие действия | По результатам анализа данного инцидента проведены организационные и технические меры. Отрегулировать конфигурацию Orchestrator, чтобы запретить перемещение первичных БД за границы региона. Ускорить миграцию на новую систему отчётности по статусам, которая предоставит более подходящую площадку для обсуждения активных инцидентов более чёткими и ясными формулировками. Сделать избыточное резервирование данных ЦОД для увеличения надёжности системы. Начать систематические проверки сценариев сбоя и возможных путей их решения до того, как они смогут повлиять на пользователей. |



